{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 10:57:27.156859: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 10:57:27.656984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-09 10:57:27.657167: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-09 10:57:29.548721: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 10:57:29.549009: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 10:57:29.549021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pygeohash as gh\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append(os.path.dirname(sys.path[0]))\n",
    "\n",
    "from python.data_cleaning import prepare_data_for_groupby\n",
    "from python.grouped_data import data_for_analysis\n",
    "from python import mlmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14723/1322138315.py:1: DtypeWarning: Columns (1,3,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_accidents=pd.read_csv('~/code/MagicaBleps/UK-road-safety/raw_data/dft-road-casualty-statistics-accident-1999-2021.csv', index_col=0)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_accidents=pd.read_csv('~/code/MagicaBleps/UK-road-safety/raw_data/dft-road-casualty-statistics-accident-1999-2021.csv', index_col=0)\n",
    "df_accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=prepare_data_for_groupby(df_accidents,6)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gcpvj0', 'gcpvhc', 'gcpvj4', 'gcpvj1', 'gcpuv2', 'gcpvh3', 'gcpvhf',\n",
       "       'gcpvh9', 'gcpvjh', 'gcpvnh'],\n",
       "      dtype='object', name='geohash')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashes=pd.DataFrame(test[['geohash','accident_year']].groupby('geohash').count())\n",
    "hashes.columns=['Accidents']\n",
    "hashes.sort_values('Accidents',inplace=True,ascending=False)\n",
    "hashes[hashes['Accidents']>=1000].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_LENGTH=416 #each fold spans over 8 years\n",
    "FOLD_STRIDE=52 #we have a fold every 1 year\n",
    "INPUT_LENGTH=10 #every X_i sequence is 10 weeks long\n",
    "TRAIN_TEST_RATIO=.80 #in each fold, we use 3 years for training and 1 year for test\n",
    "OUTPUT_LENGTH=10 #we want to predict the number of accidents in the next 10 weeks (y_i length)\n",
    "SEQUENCE_STRIDE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((190, 1, 12, 3), (190, 13, 12, 1))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=[]\n",
    "y_train=[]\n",
    "X_test=[]\n",
    "y_test=[]\n",
    "for hash in hashes[hashes['Accidents']>=1500].index:\n",
    "    data=test[test['geohash']==hash]\n",
    "    data_series=data_for_analysis(data,'W')\n",
    "    folds=mlmodel.get_folds(data_series,FOLD_LENGTH,FOLD_STRIDE)\n",
    "    for fold in folds:\n",
    "        (fold_train, fold_test) = mlmodel.train_test_split(fold, TRAIN_TEST_RATIO, INPUT_LENGTH)\n",
    "        X_train_fold, y_train_fold = mlmodel.get_X_y_strides(fold_train, INPUT_LENGTH, OUTPUT_LENGTH, SEQUENCE_STRIDE)\n",
    "        X_test_fold, y_test_fold = mlmodel.get_X_y_strides(fold_test, INPUT_LENGTH, OUTPUT_LENGTH, SEQUENCE_STRIDE)   \n",
    "        X_train.append(X_train_fold)\n",
    "        X_test.append(X_test_fold)\n",
    "        y_train.append(y_train_fold)\n",
    "        y_test.append(y_test_fold)\n",
    "np.array(X_test).shape, np.array(y_train).shape,   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all_hashes=np.array(X_train[0])\n",
    "X_test_all_hashes=np.array(X_test[0])\n",
    "y_train_all_hashes=np.array(y_train[0])\n",
    "y_test_all_hashes=np.array(y_test[0])\n",
    "\n",
    "for i in range(1,np.array(X_train).shape[0]):\n",
    "    X_train_all_hashes=np.vstack((X_train_all_hashes,X_train[i]))\n",
    "    y_train_all_hashes=np.vstack((y_train_all_hashes,y_train[i]))\n",
    "    \n",
    "for i in range(1,np.array(X_test).shape[0]):\n",
    "    X_test_all_hashes=np.vstack((X_test_all_hashes,X_test[i]))\n",
    "    y_test_all_hashes=np.vstack((y_test_all_hashes,y_test[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_all_hashes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train_all_hashes\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_all_hashes' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_all_hashes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE LSTM = 2.3\n",
      "Improvement over baseline: 21.02 % \n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "   \n",
    "baseline_model = mlmodel.init_baseline(OUTPUT_LENGTH)\n",
    "mae_baseline = baseline_model.evaluate(X_test_all_hashes, y_test_all_hashes, verbose=0)[1]\n",
    "list_of_mae_baseline_model.append(mae_baseline)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "##### LSTM Model\n",
    "model = mlmodel.init_model(X_train_all_hashes)\n",
    "es = EarlyStopping(monitor = \"val_mae\",\n",
    "                    mode = \"min\",\n",
    "                    patience = 2,\n",
    "                    restore_best_weights = True)\n",
    "history = model.fit(X_train_all_hashes, y_train_all_hashes,\n",
    "                    validation_split = 0.3,\n",
    "                    shuffle = False,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 50,\n",
    "                    callbacks = [es],\n",
    "                    verbose = 0)\n",
    "res = model.evaluate(X_test_all_hashes, y_test_all_hashes, verbose=0)\n",
    "mae_lstm = res[1]\n",
    "\n",
    "print(f\"MAE LSTM = {round(mae_lstm, 2)}\")\n",
    "\n",
    "##### Comparison LSTM vs Baseline\n",
    "print(f\"Improvement over baseline: {round((1 - (mae_lstm/mae_baseline))*100,2)} % \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('UK-road-safety')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b1aeb74382e8f893234a3f4120a1c3d15ee715275f64b4c74d4725c92433881"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
